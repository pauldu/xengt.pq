From 6321a1378698ac3e57f097b5bf0103446113ff38 Mon Sep 17 00:00:00 2001
From: Weinan Li <weinan.z.li@intel.com>
Date: Tue, 12 Jul 2016 10:03:26 +0800
Subject: [PATCH] Refine SKL MOCS save restore policy

reduce SKL MOCS save restore reg count.

Signed-off-by: Weinan Li <weinan.z.li@intel.com>
---
 drivers/gpu/drm/i915/intel_mocs.c  | 10 ++++------
 drivers/gpu/drm/i915/vgt/debugfs.c |  3 +++
 drivers/gpu/drm/i915/vgt/perf.h    |  1 +
 drivers/gpu/drm/i915/vgt/render.c  | 27 +++++++++++++++++++--------
 drivers/gpu/drm/i915/vgt/vgt.h     |  1 +
 5 files changed, 28 insertions(+), 14 deletions(-)

diff --git a/drivers/gpu/drm/i915/intel_mocs.c b/drivers/gpu/drm/i915/intel_mocs.c
index 6d3c6c0..a021b91 100644
--- a/drivers/gpu/drm/i915/intel_mocs.c
+++ b/drivers/gpu/drm/i915/intel_mocs.c
@@ -197,16 +197,14 @@ static int emit_mocs_control_table(struct drm_i915_gem_request *req,
 	}
 
 	/*
-	 * Ok, now set the unused entries to uncached. These entries
-	 * are officially undefined and no contract for the contents
-	 * and settings is given for these entries.
+	 * These entries are officially undefined and no contract for
+	 * the contents and settings is given for these entries.
 	 *
-	 * Entry 0 in the table is uncached - so we are just writing
-	 * that value to all the used entries.
+	 * we are just writing NULL value to all the used entries.
 	 */
 	for (; index < GEN9_NUM_MOCS_ENTRIES; index++) {
 		intel_logical_ring_emit(ringbuf, reg_base + index * 4);
-		intel_logical_ring_emit(ringbuf, table->table[0].control_value);
+		intel_logical_ring_emit(ringbuf, 0);
 	}
 
 	intel_logical_ring_emit(ringbuf, MI_NOOP);
diff --git a/drivers/gpu/drm/i915/vgt/debugfs.c b/drivers/gpu/drm/i915/vgt/debugfs.c
index a0a1954..4ae1ad0 100644
--- a/drivers/gpu/drm/i915/vgt/debugfs.c
+++ b/drivers/gpu/drm/i915/vgt/debugfs.c
@@ -1206,6 +1206,9 @@ struct dentry *vgt_init_debugfs(struct pgt_device *pdev)
 				&pdev->stat.ring_0_busy);
 	debugfs_create_u64_node("ring_0_idle", 0440, d_vgt_debug,
 				&pdev->stat.ring_0_idle);
+	debugfs_create_u64_node("mocs_restore_cnt", 0440, d_vgt_debug,
+				&pdev->stat.mocs_restore_cnt);
+
 
 	temp_d = debugfs_create_file("reginfo", 0444, d_vgt_debug,
 		pdev, &reginfo_fops);
diff --git a/drivers/gpu/drm/i915/vgt/perf.h b/drivers/gpu/drm/i915/vgt/perf.h
index 7972c95..6231dc6 100644
--- a/drivers/gpu/drm/i915/vgt/perf.h
+++ b/drivers/gpu/drm/i915/vgt/perf.h
@@ -113,6 +113,7 @@ struct pgt_statistics {
 	u64	oos_page_detach_cnt;
 	u64	context_switch_cost;
 	u64	context_switch_num;
+	u64	mocs_restore_cnt;
 	u64	ring_idle_wait;
 	u64	ring_0_idle;
 	u64	ring_0_busy;
diff --git a/drivers/gpu/drm/i915/vgt/render.c b/drivers/gpu/drm/i915/vgt/render.c
index 5948ded..c2b7880 100644
--- a/drivers/gpu/drm/i915/vgt/render.c
+++ b/drivers/gpu/drm/i915/vgt/render.c
@@ -290,8 +290,10 @@ static void gen9_save_mocs(struct vgt_device *vgt)
 	struct pgt_device *pdev = vgt->pdev;
 	u32 reg;
 
-	for (reg = 0xc800; reg < 0xcff8; reg += 4)
-		__vreg(vgt, reg) = VGT_MMIO_READ(pdev, reg);
+	for (reg = 0xc800; reg < 0xccfc; reg += 4) {
+		if ((reg & 0xFF) < 0x40)
+			__vreg(vgt, reg) = VGT_MMIO_READ(pdev, reg);
+	}
 
 	for (reg = 0xb020; reg < 0xb09c; reg += 4)
 		__vreg(vgt, reg) = VGT_MMIO_READ(pdev, reg);
@@ -301,15 +303,23 @@ static void gen9_restore_mocs(struct vgt_device *vgt)
 {
 	struct pgt_device *pdev = vgt->pdev;
 	u32 reg;
-
-	for (reg = 0xc800; reg < 0xcff8; reg += 4) {
-		VGT_MMIO_WRITE(pdev, reg, __vreg(vgt, reg));
-		VGT_POST_READ(pdev, reg);
+	struct vgt_device *pre_sched_vgt = pdev->pre_sched_vgt;
+
+	for (reg = 0xc800; reg < 0xccfc; reg += 4) {
+		if ((reg & 0xFF) < 0x40 &&
+			(__vreg(pre_sched_vgt, reg) != __vreg(vgt, reg))) {
+			VGT_MMIO_WRITE(pdev, reg, __vreg(vgt, reg));
+			VGT_POST_READ(pdev, reg);
+			pdev->stat.mocs_restore_cnt++;
+		}
 	}
 
 	for (reg = 0xb020; reg < 0xb09c; reg += 4) {
-		VGT_MMIO_WRITE(pdev, reg, __vreg(vgt, reg));
-		VGT_POST_READ(pdev, reg);
+		if (__vreg(pre_sched_vgt, reg) != __vreg(vgt, reg)) {
+			VGT_MMIO_WRITE(pdev, reg, __vreg(vgt, reg));
+			VGT_POST_READ(pdev, reg);
+			pdev->stat.mocs_restore_cnt++;
+		}
 	}
 }
 
@@ -592,6 +602,7 @@ bool vgt_do_render_context_switch(struct pgt_device *pdev)
 
 	next = pdev->next_sched_vgt;
 	prev = current_render_owner(pdev);
+	pdev->pre_sched_vgt = prev;
 	ASSERT(pdev->next_sched_vgt);
 	ASSERT(next != prev);
 
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index a258880..cc58253 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -460,6 +460,7 @@ struct pgt_device {
 	struct vgt_device *next_sched_vgt;
 	struct vgt_device *next_foreground_vm;
 	struct vgt_device *cur_reset_vm;	/* the VM who trigger reset */
+	struct vgt_device *pre_sched_vgt; /* the VM who has just been schedued out */
 	struct list_head rendering_runq_head; /* reuse this for context scheduler */
 	struct list_head rendering_idleq_head; /* reuse this for context scheduler */
 	spinlock_t lock;
-- 
1.9.1

